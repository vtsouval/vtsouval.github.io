<!doctype html>
<head>
  <title>Vasileios Tsouvalas</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  <link rel="preload" as="image" href="assets/misc/overview_sg.gif">
  <link href='https://fonts.googleapis.com/css?family=Roboto:300' rel='stylesheet' type='text/css'>
  <meta name="theme-color" content="#1a4067" />
  <!-- SEO -->
  <meta property="og:title" content="Vasileios Tsouvalas" />
  <meta property="og:type" content="article" />
  <meta property="og:description" content="Machine Learning Researcher" />
  <meta property="og:image" content="" />
  <meta property="og:url" content="https://vtsouval.github.io/" />
  <!-- Twitter Card data -->
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Vasileios Tsouvalas" />
  <meta name="twitter:description" content="" />
  <meta property="og:site_name" content="" />
  <meta name="twitter:image" content="" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">
  <link rel="stylesheet" href="/style.css">
</head>

<body onload="showPageCallback()">
	<script src="lib/jquery-1.12.4.min.js"></script>
	<!--<script src="lib/mobile-detect.min.js"></script>-->
	<script src="lib/template.v1.js"></script>
	<script src="lib/scramble.js"></script>
	<div id="main_body" style="display:none;">
	<dt-article id="dtbody">
	<dt-byline class="l-page transparent"></dt-byline>
	<h1>Vasileios Tsouvalas</h1>
	<h2>PhD Student @ <a href="https://www.tue.nl/en" target="_blank">Eindhoven University of Technology</a> <br>
	  Federated Learning, Human-Centric AI, Audio, & On-device ML
	</h2>
	<dt-byline class="l-page" id="authors_section">
	<div class="byline">
	  <div>
		<p>I'm a PhD student at <a class="link-colored" href="https://www.tue.nl/en">Eindhoven University of Technology</a> in the <a href="https://iris.win.tue.nl/">Interconnected Resource-aware Intelligent Systems (IRIS) group</a>. My research interests span <span class="link-colored">Machine Learning</span>, <span class="link-colored">Federated Learning</span>, <span class="link-colored">Audio</span>, <span class="link-colored">On-device ML</span>, and applications to train federated models with <span class="link-colored">minimal human supervision</span>.
		</p>
	  </div>
	  <div class="authors">
		<div class="author">
			<a class="project-link" href="https://scholar.google.com/citations?user=FgPQz3QAAAAJ&hl=en" target="_blank">Scholar</a>
		</div>
		<div class="author">
			<a class="project-link" href="https://github.com/vtsouval" target="_blank">GitHub</a>
		</div>
		<div class="author">
			<a class="project-link" href="https://www.linkedin.com/in/vasileios-tsouvalas-0a4934149/" target="_blank">LinkedIn</a>
		</div>
		<div class="author">
		<a class="project-link">Email:</a><font id="email" style="display:inline;">.vasoutetlv@una<a href="#" onclick="emailScramble.initAnimatedBubbleSort();return false;">unscramble</a></font>
		<script>
			emailScramble = new scrambledString(document.getElementById('email'),
			'emailScramble', '.vasoutetlv@unas.l',
			[1, 6, 7, 3, 4, 5, 2, 14, 12, 8, 0, 11, 13, 16, 9, 10, 15, 17]);
			</script>
		</div>
	  </div>
	</div>
	</dt-byline>

	<table valign="top">

	 <!-- project block -->
	 <tr>
	   <td class="project-fig">
		 <div class="figure">
		  <img class='project-img' src='assets/misc/overview_fedln.svg' style='width:80%;'/></div>
	   </td>
		<td class="project-cell">
		  <div class="project-title">Federated Learning with Noisy Labels</div>
		  <dt-byline>
		  <div class="byline">
		  <a class="project-link" href="https://federatedml.github.io/FedLN/" target="_blank">Project Page</a>
		  <a class="project-link" href="https://arxiv.org/pdf/2208.09378.pdf" target="_blank">PDF</a>
		  <a class="project-link" href="https://github.com/vtsouval/vtsouval.github.io/blob/master/assets/bib/tsouvalas2022federated.bib" target="_blank">BibTex</a>
		  </div><br><u>Vasileios Tsouvalas</u>, Aaqib Saeed, Tanir Ozcelebi, Nirvana Meratnia <br><br>
		Short Paper @ <a class="project-link" href="https://sites.google.com/view/interpolation-workshop" target="_blank">Interpolation and Beyond - Workshop at NeurIPS 2022</a>
		  <br><br>
		  Federated learning (FL) approaches assume high-quality labels are readily available on users' devices; in reality, label noise can naturally occur in the FL setting and follows a non-i.i.d. distribution among clients. Here, we propose FedLN, a framework to deal with label noise across different FL training stages: FL initialization, on-device model training, and server-side model aggregation.<br><br>
		  Extensive experiments on various publicly available vision and audio datasets demonstrate a 24% improvement on average compared to other existing methods for a label noise level of 70%. We further validate the efficiency of FedLN in human-annotated real-world noisy datasets and report a 9% increase on average in models' recognition performance.      
		</td>
	  </tr>

	 <!-- project block -->
	<tr>
			<td class="project-fig">
			  <div class="figure">
			   <img class='project-img' src='assets/misc/overview_fedstar.svg' style='width:95%;'/></div>
			</td>
			 <td class="project-cell">
			   <div class="project-title">Privacy-preserving Speech Emotion Recognition through Semi-Supervised Federated Learning</div>
			   <dt-byline>
			   <div class="byline">
			   <a class="project-link" href="https://arxiv.org/pdf/2202.02611.pdf" target="_blank">PDF</a>
			   <a class="project-link" href="https://dl.acm.org/doi/10.1145/3520128 " target="_blank">Link (Official)</a>
			   <!--a class="project-link" href="https://github.com/FederatedML/FedSTAR " target="_blank">Code</a-->
				   <a class="project-link" href="https://github.com/vtsouval/vtsouval.github.io/blob/master/assets/bib/tsouvalas2022fedser.bib" target="_blank">BibTex</a>
				 </div><br><u>Vasileios Tsouvalas</u>,Tanir Ozcelebi, Nirvana Meratnia @ <a class="project-link" href="https://percom.org/PerCom2022/" target="_blank">PerCom 2022</a><br><br>
			 <a class="project-link" href="https://ieeexplore.ieee.org/document/9767445" target="_blank">Short Paper</a>@ <a class="project-link" href="https://2022.ieeeicassp.org/" target="_blank"> IEEE PerCom 2022</a>
				 <br><br>
				 Speech Emotion Recognition (SER) refers to the recognition of human emotions from natural speech. If done accurately, it can offer a number of benefits in building human-centered context-aware intelligent systems. Existing SER approaches are largely centralized, without considering users' privacy. Federated Learning (FL) is a distributed machine learning paradigm dealing with decentralization of privacy-sensitive personal data. In this paper, we present a privacy-preserving and data-efficient SER approach by utilizing the concept of FL. To the best of our knowledge, this is the first federated SER approach, which utilizes self-training learning in conjunction with federated learning to exploit both labeled and unlabeled on-device data. Our experimental evaluations on the IEMOCAP dataset shows that our federated approach can learn generalizable SER models even under low availability of data labels and highly non-i.i.d. distributions. <br><br>
				 We show that our approach with as few as 10% labeled data, on average, can improve the recognition rate by 8.67% compared to the fully-supervised federated counterparts.
			 </td>
		   </tr>

	 <!-- project block -->
	  <tr>
	   <td class="project-fig">
		 <div class="figure">
		  <img class='project-img' src='assets/misc/overview_fedstar.svg' style='width:95%;'/></div>
	   </td>
		<td class="project-cell">
		  <div class="project-title">Federated Self-Training for Semi-Supervised Audio Recognition</div>
		  <dt-byline>
		  <div class="byline">
		  <a class="project-link" href="https://arxiv.org/pdf/2107.06877.pdf" target="_blank">PDF</a>
		  <a class="project-link" href="https://dl.acm.org/doi/10.1145/3520128 " target="_blank">Link (Official)</a>
		  <a class="project-link" href="https://github.com/FederatedML/FedSTAR " target="_blank">Code</a>
			  <a class="project-link" href="https://github.com/vtsouval/vtsouval.github.io/blob/master/assets/bib/tsouvalas2021federated.bib" target="_blank">BibTex</a>
			</div><br><u>Vasileios Tsouvalas</u>, Aaqib Saeed, Tanir Ozcelebi @ <a class="project-link" href="https://dl.acm.org/journal/tecs" target="_blank">ACM TECS 2022</a><br><br>
		<a class="project-link" href="https://ieeexplore.ieee.org/document/9746356" target="_blank">Short Paper</a>@ <a class="project-link" href="https://2022.ieeeicassp.org/" target="_blank"> IEEE ICASSP 2022</a>
			<br><br>
		Federated Learning is a distributed machine learning paradigm dealing with decentralized and personal datasets. Since data reside on devices like smartphones and virtual assistants, labeling is entrusted to clients or labels are extracted in an automated way for learning models. However, in the case of audio data, acquiring semantic annotations can be prohibitively expensive and time-consuming. As a result, an abundance of audio samples remains unlabeled and unexploited. We propose FedSTAR, a semi-supervised learning approach for audio recognition. FedSTAR leverages unlabeled data via self-training to improve the generalization of audio models. <br><br>
		We show that with as little as 3% labeled data available, FedSTAR on average can improve the recognition rate by 13.28% compared to the fully supervised federated model. We further demonstrate that self-supervised pre-trained models can accelerate the training of on-device models, significantly improving convergence within fewer training rounds.
		</td>
	  </tr>

	</table>
	</dt-article>
	<dt-appendix>
		<h2>Acknowledgments</h2>
		<p>This site was prepared using the <a href="https://distill.pub">Distill</a> <a href="https://github.com/distillpub/template">template</a> which is adapted and kindly open-sourced by <a href="https://sermanet.github.io/">Pierre Sermanet</a>.</p>
	</dt-appendix>
	</div>
</body>

<script>
	var block_fn;
	function showPageCallback(){
	  block_fn = setTimeout(showPage, 300);
	}
	function showPage() {
	  document.getElementById("main_body").style.display = "block";
	}
</script>

<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-79826043-1', 'auto');
	ga('send', 'pageview');
</script>
